{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2216a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter=tf.lite.Interpreter(model_path='single-pose-lightning.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd83bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES={\n",
    "    (0,1):'m',\n",
    "    (0,2):'c',\n",
    "    (1,3):'m',\n",
    "    (2,4):'c',\n",
    "    (0,5):'m',\n",
    "    (0,6):'c',\n",
    "    (5,7):'m',\n",
    "    (7,9):'m',\n",
    "    (6,8):'c',\n",
    "    (8,10):'c',\n",
    "    (5,6):'y',\n",
    "    (5,11):'m',\n",
    "    (6,12):'c',\n",
    "    (11,12):'y',\n",
    "    (11,13):'m',\n",
    "    (13,15):'m',\n",
    "    (12,14):'c',\n",
    "    (14,16):'c', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame,keypoints,confidence_threshold):\n",
    "    y,x,c=frame.shape\n",
    "    shaped=np.squeeze(np.multiply(keypoints,[y,x,1])) #re coverting from 192x192 --> 480x640  [y,x,1] 1 bsc want color chanel as it is\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky,kx,kp_conf=kp\n",
    "        if kp_conf>confidence_threshold: #selecting only part displayed in front of camera obviously part not shown will have some lesser value\n",
    "            cv2.circle(frame,(int(kx),int(ky)),4,(0,255,0),-1) #4 is size then color then -1 to fill circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21148071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame,keypoints,edges,confidence_threshold):\n",
    "    y,x,c=frame.shape\n",
    "    shaped=np.squeeze(np.multiply(keypoints,[y,x,1])) #re coverting from 192x192 --> 480x640  [y,x,1] 1 bsc want color chanel as it is\n",
    "    \n",
    "    for edge,color in edges.items():\n",
    "        p1,p2=edge\n",
    "        y1,x1,c1=shaped[p1]\n",
    "        y2,x2,c2=shaped[p2]\n",
    "        if (c1>confidence_threshold) & (c2>confidence_threshold): #selecting only part displayed in front of camera obviously part not shown will have some lesser value\n",
    "            cv2.line(frame,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_angle(frame,keypoints,p1,p2,p3,confidence_threshold):\n",
    "    y,x,c=frame.shape\n",
    "    shaped=np.squeeze(np.multiply(keypoints,[y,x,1])) #re coverting from 192x192 --> 480x640  [y,x,1] 1 bsc want color chanel as it is\n",
    "    y1,x1,c1=shaped[p1]\n",
    "    y2,x2,c2=shaped[p2]\n",
    "    y3,x3,c3=shaped[p3]\n",
    "    \n",
    "    angle=math.degrees(math.atan2(int(y3)-int(y2),int(x3)-int(x2))-math.atan2(int(y1)-int(y2),int(x1)-int(x2)))\n",
    "    if angle<0:\n",
    "        angle*=-1\n",
    "    \n",
    "    if (c1>confidence_threshold) & (c2>confidence_threshold) & (c3>confidence_threshold):\n",
    "       # cv2.line(frame,(int(x1),int(y1)),(int(x2),int(y2)),(255,255,255),3)\n",
    "        #cv2.line(frame,(int(x3),int(y3)),(int(x2),int(y2)),(255,255,255),3)\n",
    "        cv2.circle(frame,(int(x1),int(y1)),10,(0,0,255),cv2.FILLED)\n",
    "        cv2.circle(frame,(int(x1),int(y1)),15,(0,0,255),2)\n",
    "        cv2.circle(frame,(int(x2),int(y2)),10,(0,0,255),cv2.FILLED)\n",
    "        cv2.circle(frame,(int(x2),int(y2)),15,(0,0,255),2)                           \n",
    "        cv2.circle(frame,(int(x3),int(y3)),10,(0,0,255),cv2.FILLED)\n",
    "        cv2.circle(frame,(int(x3),int(y3)),15,(0,0,255),2)\n",
    "        cv2.putText(frame,str(int(angle)),(int(x2)-50,int(y2)+50),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)  \n",
    "        \n",
    "    return angle    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_reps_counting(frame,rft_hip_angle,lft_hip_angle,stage,reps):\n",
    "    if lft_hip_angle>=170 and rft_hip_angle>=170:\n",
    "        stage=\"up\"\n",
    "    elif (lft_hip_angle<=160 and rft_hip_angle<=160) and stage==\"up\":\n",
    "        stage=\"down\"\n",
    "        reps+=1\n",
    "    \n",
    "    cv2.rectangle(frame,(0,0),(225,73),(245,117,16),-1)\n",
    "    cv2.putText(frame,\"REPS\",(15,20),cv2.FONT_HERSHEY_PLAIN,2,(0,0,0),1,cv2.LINE_AA)  \n",
    "    cv2.putText(frame,str(reps),(12,50),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame,stage,(12,70),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),1,cv2.LINE_AA)\n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_exc(frame,keypoints_with_scores,stage,reps):\n",
    "    \n",
    "#     left_arm_angle=find_angle(frame,keypoints_with_scores,5,7,9,0.4)\n",
    "#     right_arm_angle=find_angle(frame,keypoints_with_scores,6,8,10,0.4)\n",
    "    left_hip_angle=find_angle(frame,keypoints_with_scores,5,11,13,0.4)\n",
    "    right_hip_angle=find_angle(frame,keypoints_with_scores,6,12,14,0.4)\n",
    "    \n",
    "    stage,reps=squat_reps_counting(frame,right_hip_angle,left_hip_angle,stage,reps)\n",
    "    \n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf72d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arm_raise_reps_counting(frame,rft_arm_angle,lft_arm_angle,rft_hip_angle,lft_hip_angle,stage,reps):\n",
    "    if (lft_arm_angle > 140 and rft_arm_angle>140) and (lft_hip_angle>=10 and rft_hip_angle>=10):\n",
    "        stage=\"up\"\n",
    "    elif (lft_arm_angle > 160 and rft_arm_angle>160) and (lft_hip_angle<=10 and rft_hip_angle<=10) and stage==\"up\":\n",
    "        stage=\"down\"\n",
    "        reps+=1\n",
    "    \n",
    "    cv2.rectangle(frame,(0,0),(225,73),(245,117,16),-1)\n",
    "    cv2.putText(frame,\"REPS\",(15,20),cv2.FONT_HERSHEY_PLAIN,2,(0,0,0),1,cv2.LINE_AA)  \n",
    "    cv2.putText(frame,str(reps),(12,50),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame,stage,(12,70),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),1,cv2.LINE_AA)\n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e52840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arm_raise_exc(frame,keypoints_with_scores,stage,reps):\n",
    "    \n",
    "    left_arm_angle=find_angle(frame,keypoints_with_scores,5,7,9,0.4)\n",
    "    right_arm_angle=find_angle(frame,keypoints_with_scores,6,8,10,0.4)\n",
    "    left_hip_angle=find_angle(frame,keypoints_with_scores,5,11,7,0.4)\n",
    "    right_hip_angle=find_angle(frame,keypoints_with_scores,6,12,8,0.4)\n",
    "    \n",
    "    stage,reps=arm_raise_reps_counting(frame,right_arm_angle,left_arm_angle,right_hip_angle,left_hip_angle,stage,reps)\n",
    "    \n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_raise_reps_counting(frame,rft_angle,lft_angle,stage,reps):\n",
    "    if lft_angle > 160 and rft_angle>160:\n",
    "        stage=\"down\"\n",
    "    elif (lft_angle < 30 and rft_angle < 30) and stage==\"down\":\n",
    "        stage=\"up\"\n",
    "        reps+=1\n",
    "    \n",
    "    cv2.rectangle(frame,(0,0),(225,73),(245,117,16),-1)\n",
    "    cv2.putText(frame,\"REPS\",(15,20),cv2.FONT_HERSHEY_PLAIN,2,(0,0,0),1,cv2.LINE_AA)  \n",
    "    cv2.putText(frame,str(reps),(12,50),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame,stage,(12,70),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),1,cv2.LINE_AA)\n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33958ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_raise_exc(frame,keypoints_with_scores,stage,reps):\n",
    "    \n",
    "    left_arm_angle=find_angle(frame,keypoints_with_scores,5,7,9,0.4)\n",
    "    right_arm_angle=find_angle(frame,keypoints_with_scores,6,8,10,0.4)\n",
    "    left_hip_angle=find_angle(frame,keypoints_with_scores,5,11,7,0.4)\n",
    "    right_hip_angle=find_angle(frame,keypoints_with_scores,6,12,8,0.4)\n",
    "    \n",
    "    stage,reps=front_raise_reps_counting(frame,right_arm_angle,left_arm_angle,stage,reps)\n",
    "    \n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushups_reps_counting(frame,rft_angle,lft_angle,stage,reps):\n",
    "    if lft_angle > 160 and rft_angle>160:\n",
    "        stage=\"up\"\n",
    "    if (lft_angle <= 65 and rft_angle <= 65) and stage==\"up\":\n",
    "        stage=\"down\"\n",
    "        reps+=1\n",
    "    \n",
    "    cv2.rectangle(frame,(0,0),(225,73),(245,117,16),-1)\n",
    "    cv2.putText(frame,\"REPS\",(15,20),cv2.FONT_HERSHEY_PLAIN,2,(0,0,0),1,cv2.LINE_AA)  \n",
    "    cv2.putText(frame,str(reps),(12,50),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame,stage,(12,70),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),1,cv2.LINE_AA)\n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb53610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushups_exc(frame,keypoints_with_scores,stage,reps):\n",
    "    \n",
    "    left_angle=0\n",
    "    left_angle=find_angle(frame,keypoints_with_scores,5,7,9,0.4)\n",
    "    right_angle=find_angle(frame,keypoints_with_scores,6,8,10,0.4)\n",
    "    \n",
    "    stage,reps=pushups_reps_counting(frame,right_angle,left_angle,stage,reps)\n",
    "    \n",
    "    return stage,reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9326b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yuv420_to_rgb(yuv_data):\n",
    "    width, height = 720, 480  # Set these to the actual resolution of the camera\n",
    "    y_size = width * height\n",
    "    uv_size = (width // 2) * (height // 2)\n",
    "\n",
    "    # Ensure the length matches the expected YUV420 size\n",
    "    if len(yuv_data) != y_size + 2 * uv_size:\n",
    "        raise ValueError(\"Invalid YUV420 data length\")\n",
    "\n",
    "    y = np.frombuffer(yuv_data[:y_size], dtype=np.uint8).reshape((height, width))\n",
    "    u = np.frombuffer(yuv_data[y_size:y_size + uv_size], dtype=np.uint8).reshape((height // 2, width // 2))\n",
    "    v = np.frombuffer(yuv_data[y_size + uv_size:], dtype=np.uint8).reshape((height // 2, width // 2))\n",
    "\n",
    "    # Resize U and V planes to match the size of the Y plane\n",
    "    u = cv2.resize(u, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "    v = cv2.resize(v, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Stack Y, U, and V planes along the third dimension\n",
    "    yuv = np.dstack((y, u, v))\n",
    "    rgb = cv2.cvtColor(yuv, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81151980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_anticlockwise(image):\n",
    "    # Rotate the image 90 degrees anti-clockwise\n",
    "    return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, WebSocket\n",
    "import uvicorn\n",
    "import cv2, base64\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import io\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=FastAPI()\n",
    "\n",
    "# Allow CORS for all origins\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.websocket(\"/ws\")\n",
    "async def websocket_endpoint(websocket: WebSocket):\n",
    "    await websocket.accept()\n",
    "    temp_video_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')\n",
    "    output_video_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')\n",
    "    try:\n",
    "        while True:\n",
    "            data = await websocket.receive_text()\n",
    "\n",
    "            if data.startswith(\"set_exercise\"):\n",
    "                exercise_value = data.split(\"=\")[1]\n",
    "                exercise = exercise_value\n",
    "\n",
    "            elif data == \"start_video\":\n",
    "                # Receive the video file\n",
    "                video_bytes = await websocket.receive_bytes()\n",
    "                temp_video_file.write(video_bytes)\n",
    "                temp_video_file.close()\n",
    "                print('Video recieved')\n",
    "\n",
    "                # Open the video using cv2.VideoCapture\n",
    "                cap = cv2.VideoCapture(temp_video_file.name)\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                out = cv2.VideoWriter(output_video_file.name, fourcc, fps, (width, height))\n",
    "\n",
    "                reps=0\n",
    "                stage=None\n",
    "\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "\n",
    "                    img = frame.copy()\n",
    "                    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192)\n",
    "                    input_img = tf.cast(img, dtype=tf.float32)  # [192,192,3] float32\n",
    "\n",
    "                    # Input and output arrays\n",
    "                    input_details = interpreter.get_input_details()\n",
    "                    output_details = interpreter.get_output_details()\n",
    "\n",
    "                    # Pass to tensor to get predictions\n",
    "                    interpreter.set_tensor(input_details[0]['index'], np.array(input_img))\n",
    "                    interpreter.invoke()\n",
    "                    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "                    draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "                    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "                    if exercise=='front_raise':\n",
    "                        stage,reps=front_raise_exc(frame,keypoints_with_scores,stage,reps)\n",
    "\n",
    "                    elif exercise=='push_ups':\n",
    "                        stage,reps=pushups_exc(frame,keypoints_with_scores,stage,reps)\n",
    "\n",
    "                    elif exercise=='arm_raise':\n",
    "                        stage,reps=arm_raise_exc(frame,keypoints_with_scores,stage,reps)\n",
    "\n",
    "                    elif exercise=='squat':\n",
    "                        stage,reps=squat_exc(frame,keypoints_with_scores,stage,reps)  \n",
    "\n",
    "                    out.write(frame)\n",
    "\n",
    "                cap.release()\n",
    "                out.release()\n",
    "\n",
    "                # Read the processed video file and send it to Flutter\n",
    "                with open(output_video_file.name, 'rb') as f:\n",
    "                    video_data = f.read()\n",
    "                    await websocket.send_bytes(video_data)\n",
    "                    print('Video sent')\n",
    "\n",
    "    finally:\n",
    "        os.remove(temp_video_file.name)\n",
    "        os.remove(output_video_file.name)\n",
    "        await websocket.close()\n",
    "    \n",
    "def run_server():\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        # Run in the current running loop\n",
    "        loop.create_task(server.serve())\n",
    "    else:\n",
    "        # Run normally if no loop is running\n",
    "        loop.run_until_complete(server.serve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792acb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
